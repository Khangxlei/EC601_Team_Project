# -*- coding: utf-8 -*-
"""main

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17gI4wt6P3diFw8_M_dSedXwNwRCCUfnn
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import yfinance as yf
import numpy as np
import pandas as pd
import requests
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from typing import List, Dict, Optional
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI()

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Define valid periods
valid_periods = ["6mo", "1y", "2y", "5y", "10y", "ytd", "max"]

# FRED API configuration
FRED_API_KEY = "028dd256cbdb1a33b5f5873d225df899"

# Define models
class Trade(BaseModel):
    date: str
    action: str
    shares: int
    price: float
    balance: float

class PredictionItem(BaseModel):
    date: str
    actual: Optional[float] = None
    predicted: float

class PredictionRequest(BaseModel):
    ticker: str
    period: str
    initial_balance: float
    future_days: int = 0

class PredictionResponse(BaseModel):
    initial_balance: float
    final_balance: float
    profit_loss: Optional[float] = None
    rmse: float
    trade_log: List[Trade]
    predictions: List[PredictionItem]

# Utility functions
def fetch_fred_data(series_id, start_date, end_date):
    """Fetch economic data from FRED."""
    url = "https://api.stlouisfed.org/fred/series/observations"
    params = {
        "series_id": series_id,
        "api_key": FRED_API_KEY,
        "file_type": "json",
        "observation_start": start_date,
        "observation_end": end_date
    }
    response = requests.get(url, params=params)
    if response.status_code == 200:
        data = response.json()
        df = pd.DataFrame(data["observations"])
        df["date"] = pd.to_datetime(df["date"])
        df["value"] = pd.to_numeric(df["value"], errors='coerce')
        return df.set_index("date")["value"]
    return None

def get_economic_indicators(start_date, end_date):
    """Fetch multiple economic indicators."""
    indicators = {
        "CPIAUCSL": "inflation",         # Consumer Price Index
        "FEDFUNDS": "interest_rate",     # Federal Funds Rate
        "UNRATE": "unemployment",        # Unemployment Rate
        "A191RL1Q225SBEA": "gdp_growth" # Real GDP Growth
    }

    economic_data = pd.DataFrame()
    for series_id, name in indicators.items():
        data = fetch_fred_data(series_id, start_date, end_date)
        if data is not None:
            economic_data[name] = data

    return economic_data.ffill().fillna(0)

def download_stock_data(ticker, period="5y"):
    if period not in valid_periods:
        raise HTTPException(status_code=400, detail=f"Invalid period. Must be one of: {', '.join(valid_periods)}")
    stock_data = yf.download(ticker, period=period)
    return stock_data

def preprocess_data(stock_data, economic_data, feature_col="Close", seq_length=60):
    try:
        seq_length = int(float(seq_length))
    except (ValueError, TypeError):
        raise HTTPException(status_code=400, detail=f"Invalid sequence length: {seq_length}")

    # Align timestamps
    stock_data.index = stock_data.index.tz_localize(None)
    economic_data.index = economic_data.index.tz_localize(None)

    # Reindex economic data to match stock data dates
    economic_data = economic_data.reindex(stock_data.index).ffill().fillna(0)

    # Scale the data
    stock_scaler = MinMaxScaler(feature_range=(0, 1))
    economic_scaler = MinMaxScaler(feature_range=(0, 1))

    scaled_stock = stock_scaler.fit_transform(stock_data[[feature_col]])
    scaled_economic = economic_scaler.fit_transform(economic_data)

    # Combine features
    combined_data = np.hstack((scaled_stock, scaled_economic))

    X, y = [], []
    for i in range(seq_length, len(combined_data)):
        X.append(combined_data[i-seq_length:i])
        y.append(scaled_stock[i, 0])

    X, y = np.array(X), np.array(y)
    return X, y, stock_scaler

def create_lstm_model(input_shape):
    model = Sequential([
        LSTM(50, return_sequences=True, input_shape=input_shape),
        Dropout(0.2),
        LSTM(25, return_sequences=False),
        Dropout(0.2),
        Dense(10),
        Dense(1)
    ])
    model.compile(optimizer="adam", loss="mse")
    return model

def train_lstm_model(model, X_train, y_train, epochs=10, batch_size=32):
    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)
    return model

def predict_future(model, last_sequence, days, scaler):
    future_predictions = []
    current_sequence = last_sequence.copy()

    for _ in range(days):
        pred = model.predict(current_sequence.reshape(1, -1, current_sequence.shape[-1]))
        future_predictions.append(scaler.inverse_transform(pred)[0][0])
        # Update sequence with prediction and zero values for economic indicators
        current_sequence = np.append(current_sequence[1:],
                                   np.hstack((pred, np.zeros((1, current_sequence.shape[-1]-1)))),
                                   axis=0)
    return future_predictions

def simulate_trading(predictions, actual_prices, dates, initial_balance=10000, shares=0):
    balance = initial_balance
    total_shares = shares
    trade_log = []

    for i in range(1, len(predictions)):
        predicted_price = predictions[i]
        actual_price = actual_prices[i]
        date = dates[i]

        # Handle any NaN values
        if np.isnan(predicted_price) or np.isnan(actual_price):
            continue

        if predicted_price > actual_prices[i-1] and balance >= actual_price:
            shares_to_buy = balance // actual_price
            balance -= shares_to_buy * actual_price
            total_shares += shares_to_buy
            trade_log.append(Trade(
                date=str(date),
                action="Bought",
                shares=int(shares_to_buy),
                price=float(actual_price),
                balance=float(balance)
            ))

        elif predicted_price < actual_prices[i-1] and total_shares > 0:
            balance += total_shares * actual_price
            trade_log.append(Trade(
                date=str(date),
                action="Sold",
                shares=int(total_shares),
                price=float(actual_price),
                balance=float(balance)
            ))
            total_shares = 0

    if total_shares > 0:
        balance += total_shares * actual_prices[-1]
        trade_log.append(Trade(
            date=str(dates[-1]),
            action="Sold",
            shares=int(total_shares),
            price=float(actual_prices[-1]),
            balance=float(balance)
        ))

    profit_loss = balance - initial_balance
    return trade_log, profit_loss

@app.post("/api/predict", response_model=PredictionResponse)
async def predict_stock(request: PredictionRequest):
    try:
        if request.period not in valid_periods:
            raise HTTPException(status_code=400, detail=f"Invalid period. Must be one of: {', '.join(valid_periods)}")

        if request.future_days < 0 or request.future_days > 365:
            raise HTTPException(status_code=400, detail="Future days must be between 0 and 365")

        # Download stock data
        stock_data = download_stock_data(request.ticker, request.period)
        start_date = stock_data.index[0].strftime('%Y-%m-%d')
        end_date = stock_data.index[-1].strftime('%Y-%m-%d')

        # Get economic indicators
        economic_data = get_economic_indicators(start_date, end_date)

        # Preprocess the data
        X, y, scaler = preprocess_data(stock_data, economic_data)

        # Split data
        split_idx = int(len(X) * 0.8)
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]

        # Train model
        model = create_lstm_model((X_train.shape[1], X_train.shape[2]))
        model = train_lstm_model(model, X_train, y_train)

        # Make predictions
        predictions = model.predict(X_test)
        predictions = scaler.inverse_transform(predictions)
        actual_prices = scaler.inverse_transform(y_test.reshape(-1, 1))

        # Handle NaN values
        predictions = np.nan_to_num(predictions, nan=0.0)
        actual_prices = np.nan_to_num(actual_prices, nan=0.0)

        # Calculate RMSE
        rmse = float(np.sqrt(np.mean((predictions - actual_prices) ** 2)))

        # Generate predictions list
        test_dates = stock_data.index[split_idx + 60:].strftime("%Y-%m-%d").tolist()

        all_predictions = []
        for i in range(len(test_dates)):
            pred_value = float(predictions[i][0])
            actual_value = float(actual_prices[i][0])

            # Ensure values are within JSON-compatible range
            if np.isfinite(pred_value) and np.isfinite(actual_value):
                all_predictions.append(
                    PredictionItem(
                        date=test_dates[i],
                        actual=actual_value,
                        predicted=pred_value
                    )
                )

        # Generate future predictions if requested
        if request.future_days > 0:
            last_sequence = X_test[-1]
            future_predictions = predict_future(model, last_sequence, request.future_days, scaler)
            future_dates = pd.date_range(stock_data.index[-1], periods=request.future_days + 1, freq="B")[1:]

            for i in range(len(future_predictions)):
                pred_value = float(future_predictions[i])
                if np.isfinite(pred_value):
                    all_predictions.append(
                        PredictionItem(
                            date=str(future_dates[i].date()),
                            actual=None,
                            predicted=pred_value
                        )
                    )

        # Simulate trading
        trade_log, profit_loss = simulate_trading(
            predictions.flatten(),
            actual_prices.flatten(),
            test_dates,
            request.initial_balance
        )

        return PredictionResponse(
            initial_balance=request.initial_balance,
            final_balance=trade_log[-1].balance if trade_log else request.initial_balance,
            profit_loss=profit_loss,
            rmse=rmse,
            trade_log=trade_log,
            predictions=all_predictions,
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

